<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="接了个项目,之前没接触过人工智能,机器学习,深度学习,神经网络,计算机视觉…稍微了解一下">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习名词辨析">
<meta property="og:url" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="hzlg&#39;s blog">
<meta property="og:description" content="接了个项目,之前没接触过人工智能,机器学习,深度学习,神经网络,计算机视觉…稍微了解一下">
<meta property="og:locale">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/image-20230413224245229.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674890690412.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069021.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069022.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069023.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069024.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069025.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069026.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069037.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069038.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069039.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674890690310.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674890690311.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828525.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828626.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828627.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828628.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828629.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828630.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828631.png">
<meta property="article:published_time" content="2022-10-09T16:00:00.000Z">
<meta property="article:modified_time" content="2022-10-09T16:00:00.000Z">
<meta property="article:author" content="hzlg">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/image-20230413224245229.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://hzlg.github.ioz/2022/10/10/机器学习/基础/机器学习概念入门/"/>





  <title>机器学习名词辨析 | hzlg's blog</title>
  














<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">hzlg's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">笔记、日常</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hzlg.github.ioz/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hzlg's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习名词辨析</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-10-10T00:00:00+08:00">
                2022-10-10
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2022-10-10T00:00:00+08:00">
                2022-10-10
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>接了个项目,之前没接触过人工智能,机器学习,深度学习,神经网络,计算机视觉…稍微了解一下</p>
<span id="more"></span>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/159189617">机器学习准则（期望风险、经验风险、结构风险） - 知乎 (zhihu.com)</a></p>
<blockquote>
<p>损失函数：度量模型一次预测的好坏</p>
<p>风险函数：度量平均意义下的模型预测好坏</p>
<p>知道真实的分布,选择期望风险(积分)最小的模型就行,不过不知道分布,只能经验风险(均值),结构风险(经验风险+正则化)</p>
</blockquote>
<p>Normalization，Regularization 和 standardization</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/59939602">(8 封私信) 如何理解Normalization，Regularization 和 standardization？ - 知乎 (zhihu.com)</a></p>
<blockquote>
<p>归一化(消除量纲影响)和标准化(消除特征偏见)都是为了减小极端值的影响,正则化是对模型添加限制防止过拟合</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/60793482">(8 封私信) 如何理解和区分近似误差和估计误差? - 知乎 (zhihu.com)</a></p>
<blockquote>
<p>近似误差 : 模型假设空间内的最优解与真实世界最优解的误差,假设空间足够大就可以消除近似误差(模型选择时 模型不适合数据会有有近似误差)</p>
<p>估计误差 : 搜索到的解和模型假设空间内的最优解的误差(模型训练 的过程就是降低估计误差的过程,可以期望风险最小化、经验风险最小化和结构风险最小化…)</p>
<img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/image-20230413224245229.png" alt="image-20230413224245229" style="zoom:50%;"> 
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/138068036">面向小白的深度学习论文术语（持续更新） - 知乎 (zhihu.com)</a></p>
<h2 id="人工智能大纲-学习路线-资源"><a href="#人工智能大纲-学习路线-资源" class="headerlink" title="人工智能大纲/学习路线/资源"></a>人工智能大纲/学习路线/资源</h2><blockquote>
<p>Reference:</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/128986471">浅谈人工智能领域各个方向</a></p>
</blockquote>
<img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674890690412.png" alt="img" style="zoom:50%;"> 

<p>人工智能主要有三种算法:强化学习，机器学习，深度学习</p>
<p><code>机器学习</code>包括统计学习概论，感知机，朴素贝叶斯，决策树，逻辑回归和最大熵，提升树等等 </p>
<p><code>深度学习</code>是一种模拟人脑<code>神经网络</code>并识别并创建用于决策的模式的技术，和这个项目有关的就是计算机视觉方面，包括<code>反向传播</code>梯度回传，<code>损失函数</code>，优化算法，<code>多层感知机</code>，<code>卷积神经网络CNN</code>，循环神经网络等等 </p>
<p>应用的领域:<code>计算机视觉CV</code>、自然语言、语音、知识图谱这几大方向</p>
<p>老师搞的是计算机视觉，CV的子方向有:<code>目标检测</code>、<code>目标识别</code>、<code>图像分类</code>、图像分割、图像内容理解、<code>姿态估计</code>、SLAM(定位和地图构建)等等</p>
<h3 id="路线-资源"><a href="#路线-资源" class="headerlink" title="路线/资源"></a>路线/资源</h3><blockquote>
<p>Reference：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1yg411K72z/?spm_id_from=333.788.recommend_more_video.0&vd_source=6f0936ead220536edebc1dda72c5721a">三个月从零入门深度学习，保姆级学习路线图_哔哩哔哩_bilibili</a></p>
</blockquote>
<p>每个阶段的各种博客啥的，不全打出来了，看↑这个视频有讲</p>
<p>工具可以用谷歌的TensorFlow或者Facebook的<code>Pytorch</code>，Pytorch比较简单，可以看b站刘二大人的视频<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Y7411d7Ys/?spm_id_from=333.999.0.0">《PyTorch深度学习实践》完结合集_哔哩哔哩_bilibili</a></p>
<p>吴恩达的机器学习很有名，放个链接在这码着[<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV164411b7dx/?spm_id_from=333.337.search-card.all.click&vd_source=6f0936ead220536edebc1dda72c5721a">中英字幕]吴恩达机器学习系列课程_哔哩哔哩_bilibili</a></p>
<p>计算机视觉cs231n也挺有名的，链接:<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1nJ411z7fe/?spm_id_from=333.337.search-card.all.click&vd_source=6f0936ead220536edebc1dda72c5721a">【公开课】最新斯坦福李飞飞cs231n计算机视觉课程【附中文字幕】_哔哩哔哩_bilibili</a></p>
<p>舍友有本西瓜书，但是貌似不是很适合入门</p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><blockquote>
<p>太长不看版:全连接神经网络里有很多神经元，全部都连接了起来，神经元接收很多个输入，加权求和之后输出，权重可以不断修改，根据梯度下降算法和反向传播算法一直试一直学习就能找到损失函数最小时的参数，神经网络可以当做是能够拟合任意函数的黑盒子，只要训练数据足够，给定特定的x，就能得到希望的y，主要用于解决回归问题或分类问题</p>
</blockquote>
<p>找到个能总结下面全部东西的：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1FP411j7oW/?spm_id_from=333.788&vd_source=6f0936ead220536edebc1dda72c5721a">学习分享一年，对神经网络的理解全都在这40分钟里了_哔哩哔哩_bilibili</a></p>
</blockquote>
<h3 id="神经元-激活函数"><a href="#神经元-激活函数" class="headerlink" title="神经元/激活函数"></a>神经元/激活函数</h3><blockquote>
<p>Reference:</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Hr4y1q7Y1/?spm_id_from=333.788.recommend_more_video.-1&vd_source=6f0936ead220536edebc1dda72c5721a">什么是神经网络？看一个动画，就全明白了哔哩哔哩bilibili</a></p>
</blockquote>
<p>神经元的具体工作就是将不同输入<code>加权求和</code>再加一个<code>偏置b</code>，得到结果z，z经过<code>激活函数</code>得到神经元的输出y</p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069021.png" alt="img"> </p>
</blockquote>
<p><code>激活函数</code>的作用是将非线性特征引入神经元，使得神经网络能够任意逼近任何非线性函数，用于模拟人脑部神经元对输入的信息进行<strong>处理</strong> 并 <strong>判断是否产生对应的响应(神经元是否要兴奋)</strong></p>
<p>常见的激活函数有<code>Sigmoid函数</code>，<code>阶跃函数</code>，<code>ReLU函数</code>，<code>Tanh函数</code>等</p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069022.png" alt="img"> </p>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069023.png" alt="img"><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069024.png" alt="img"></p>
</blockquote>
<h3 id="感知机-损失函数-梯度下降"><a href="#感知机-损失函数-梯度下降" class="headerlink" title="感知机/损失函数/梯度下降"></a>感知机/损失函数/梯度下降</h3><blockquote>
<p>References:</p>
<p><a target="_blank" rel="noopener" href="https://cxybb.com/article/Mr_health/107516784">【神经网络】神经元模型和感知器_Mr_health的博客-程序员宝宝_感知器与神经元 - 程序员宝宝</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/113714840">什么是梯度下降</a></p>
<p>[神经网络模型及其应用](<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/444158880#:~:text=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8">https://zhuanlan.zhihu.com/p/444158880#:~:text=神经网络模型及其应用</a> 1 1. 引言 神经网络（Neural Network）也被称为人工神经网络，是深度学习算法的核心。 它的灵感来源于人脑内部的神经元，模仿生物神经元之间相互传递信号的方式，从而达到学习经验的目的。 1943年，神经生理学家,神经网络模型是模仿人脑神经元而来。 … 3 3. 应用实例 3.1. 分类问题 )</p>
</blockquote>
<p><code>感知机</code>和神经元差不多，不过神经元的输入权重不会变，感知机可以采用<strong>有监督的方式</strong>学习到参数值，即可以利用<code>梯度下降算法</code>来自主更新参数</p>
<p><code>损失函数</code>:错误分类的数据到当前用于划分的直线的距离和(应该就是度量划分误差的)，常见的损失函数有<code>均方误差函数</code>MSE和<code>交叉熵损失函数</code>CEE</p>
<p><code>梯度下降</code>:寻找目标函数最小化的方法，此处就是想让<code>损失函数</code>最小</p>
<p>具体来说:目标函数 J(θ) 关于参数 θ 的梯度将是损失函数(loss function)上升最快的方向。而我们要最小化loss，只需要将参数沿着梯度相反的方向前进一个步长，就可以实现损失函数的下降。这个步长 η 又称为学习速率。</p>
<p>感知器学习的过程就是根据误差不断<code>调节参数</code>的过程</p>
<p>比如给两类的数据，让你把数据分开，就画一条直线，每放一个数据就算一个损失函数判断是否分开了，没分开的话就梯度下降，斜率变动一点点，直到最后损失函数很小，能较好的分开数据</p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069025.png" alt="img"> </p>
</blockquote>
<h3 id="多层感知机-反向传播"><a href="#多层感知机-反向传播" class="headerlink" title="多层感知机/反向传播"></a>多层感知机/反向传播</h3><blockquote>
<p>Reference:</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39723678/article/details/111107581">多层感知机和神经网络的区别_一文了解人工智能神经网络的原理_weixin_39723678的博客-CSDN博客</a></p>
<p>[神经网络模型及其应用](<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/444158880#:~:text=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8">https://zhuanlan.zhihu.com/p/444158880#:~:text=神经网络模型及其应用</a> 1 1. 引言 神经网络（Neural Network）也被称为人工神经网络，是深度学习算法的核心。 它的灵感来源于人脑内部的神经元，模仿生物神经元之间相互传递信号的方式，从而达到学习经验的目的。 1943年，神经生理学家,神经网络模型是模仿人脑神经元而来。 … 3 3. 应用实例 3.1. 分类问题 )</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1QV4y1E7eA/?spm_id_from=333.788.recommend_more_video.-1&vd_source=6f0936ead220536edebc1dda72c5721a">5分钟-通俗易懂 - 神经网络 反向传播算法(手算)_哔哩哔哩_bilibili</a></p>
</blockquote>
<p>单层感知机只能解决线性可分问题，而且不能解决异或问题，就增加层数，搞成<code>多层感知机</code>，并加入<code>反向传播算法</code></p>
<p>神经元被分为输入层(接收原始特征信息)，隐藏层(可以有多层，进行特征信息的提取和加工)，输出层(输出结果)。</p>
<p><code>反向传播</code>:我们建立神经网络模型的最终目的是使用模型对现实问题进行预测，在给定网络结构之后，需要训练神经网络并<code>更新参数</code>，通常训练神经网络都会采用梯度下降法或其改进方法，其中最关键的是<strong>求解出损失函数对各参数的梯度</strong>。<code>反向传播算法</code>就是用来<strong>计算神经网络对其参数梯度</strong>的一种算法。利用反向传播算法算出参数的梯度就能结合学习率更新参数，减小误差</p>
<h3 id="神经网络的作用-本质"><a href="#神经网络的作用-本质" class="headerlink" title="神经网络的作用/本质"></a>神经网络的作用/本质</h3><blockquote>
<p>Reference:</p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1604194">回归和分类的区别</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/shuiyixin/article/details/88816416">【机器学习小常识】“分类” 与 “回归”的概念及区别详解_水亦心的博客-CSDN博客_分类和回归</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19B4y1M7z8/?spm_id_from=333.788.recommend_more_video.2&vd_source=6f0936ead220536edebc1dda72c5721a">神经网络本质_哔哩哔哩_bilibili</a></p>
</blockquote>
<p>神经网络可以用来做回归/分类问题</p>
<p><code>回归/函数逼近问题</code>:回归的目的是为了找到最优拟合，通过回归算法得到是一个最优拟合线，这个线条可以最好的接近数据集中的各个点。通常是用来预测一个<strong>定量的值</strong>，如预测房价、未来的天气情况等等，例如一个产品的实际价格为500元，回归要做的是就是<strong>找到一个数学公式能相对较完美地把所有自变量组合(加减乘除)起来，得到的结果值和目标值接近</strong>，通过回归分析预测值为499元，我们认为这是一个比较好的回归分析。一个比较常见的回归算法是线性回归算法(LR)。另外，回归分析用在神经网络上，其最上层是不需要加上softmax函数的，而是直接对前一层累加即可。回归是对真实值的一种逼近预测。</p>
<p><code>分类问题</code>:分类的目的是为了寻找决策边界，即分类算法得到是一个决策面，用于对数据集中的数据进行分类，通常结果为用于<strong>定性的离散值</strong>。例如判断一幅图片上的动物是一只猫还是一只狗，分类通常是建立在回归之上，分类的最后一层通常要使用softmax函数进行判断其所属类别。分类并没有逼近的概念，最终正确结果只有一个，错误的就是错误的，不会有相近的概念。最常见的分类方法是逻辑回归，或者叫逻辑分类。</p>
<p>神经网络的本质就是个超复杂的函数，实现m维向量到n维向量的转变，对数据的原始分布进行不断地变换空间和映射，最终变得线性可分</p>
<h2 id="卷积神经网络CNN"><a href="#卷积神经网络CNN" class="headerlink" title="卷积神经网络CNN"></a>卷积神经网络CNN</h2><blockquote>
<p>太长不看版:全连接网络的参数往往十分巨大，训练效率极低，为了图像处理，识别等问题就提出了卷积神经网络</p>
<p><code>卷积层</code>提取图像特征，<code>池化层</code>进行特征选择，过滤信息，从而减小数据量，提升效率，<code>全连接层</code>根据最后的特征与样本的相似度做判断</p>
</blockquote>
<h3 id="历史发展"><a href="#历史发展" class="headerlink" title="历史发展"></a>历史发展</h3><blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069026.png" alt="img"> </p>
</blockquote>
<h3 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h3><p>输入层、卷积层、池化层和全连接层</p>
<blockquote>
<p>Reference:</p>
<p>这个视频讲的比较通俗易懂:<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1AL4y1b7er/?spm_id_from=333.788.recommend_more_video.6&vd_source=6f0936ead220536edebc1dda72c5721a">3分钟看懂图像识别和卷积神经网络_哔哩哔哩_bilibili</a></p>
<p>这个文章比较详细，但抽象一些:<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/47184529">卷积神经网络(CNN)详解</a></p>
</blockquote>
<p><strong>卷积层</strong>：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VV411478E/?zw">从“卷积”、到“图像卷积操作”、再到“卷积神经网络”，“卷积”意义的3次改变_哔哩哔哩_bilibili</a> </p>
</blockquote>
<p>感觉↑这个up讲的挺好的，思路很流畅</p>
<p>卷积的作用:</p>
<p>若有一个系统的输入是不稳定的，输出是稳定的，就可以用卷积(翻转再加权求和)求系统存量。此处卷积的作用是<strong>求前一段时间对当前时间点的影响</strong>。 </p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069037.png" alt="img"> </p>
</blockquote>
<p>在卷积神经网络识别图像内容的时候，会先对图像进行卷积操作再交给神经网络，而对图像的卷积操作就是拿一个3<em>3的点阵(卷积核)罩在图片上，卷积核上的值和像素值加权求和，得到的结果作为新像素的值。此处卷积的作用是*<em>求周围不同距离的像素点对当前像素点的影响</em></em></p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069038.png" alt="img"> </p>
</blockquote>
<p>卷积神经网络还可以从输入中<strong>提取局部特征</strong>，组成更高阶的特征张量，或者说像一个<strong>滤波器</strong>，把主要的特征滤出来</p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-16667489069039.png" alt="img"> </p>
</blockquote>
<p>看完上面的视频再看这个↓就挺直观的</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1AA411778b/?spm_id_from=333.788.recommend_more_video.3&vd_source=6f0936ead220536edebc1dda72c5721a">科普动画秒懂-深度学习之卷积神经网络(DL-CNN)_哔哩哔哩_bilibili</a></p>
</blockquote>
<h2 id="生成对抗网络GAN"><a href="#生成对抗网络GAN" class="headerlink" title="生成对抗网络GAN"></a>生成对抗网络GAN</h2><blockquote>
<p>太长不看版:GAN里有个生成器(造假币的)，有个判别器(警察)，生成器不断造假，判别器不断识别，一直对抗直到判别器识别不出真假了，就认为生成器造假能力挺牛的</p>
</blockquote>
<blockquote>
<p>Reference:</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41012765/article/details/125711857">GAN网络_牵一发而动全身的博客-CSDN博客_gan网络</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28853704">GAN入门理解及公式推导</a></p>
</blockquote>
<p>生成对抗网络(GAN， Generative Adversarial Networks)是一种深度学习模型。主要包括两部分:<strong>生成模型</strong>和<strong>判别模型</strong>。</p>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674890690310.png" alt="img"></p>
<ul>
<li><p><code>生成器G</code>是一个<strong>生成假图片</strong>的网络，它接收一个随机的噪声z，通过这个噪声生成图片，生成的图片记做G(z)。</p>
</li>
<li><p><code>判别器D</code>判别一张图片<strong>是不是“真实的”</strong>。它的输入是x(一张图片，包含生成的假图片和真实图片)， 输出D(x)代表图片x为真实图片的概率，如果D(x)为1，就代表100%是真实的图片，而输出D(x)为0，就代表图片0%是真的(或者说100%是假的)</p>
</li>
</ul>
<p>生成器与判别器互相对抗，不断调整参数。最终的目的是使判别网络无法判断生成网络的输出结果是否真实。</p>
<p>对于判别网络，可以认为是<code>二分类问题</code>(给你个图片看看是不是猫咪，是就输出1不是就输出0)，二分类问题的<code>损失函数</code>可以使用<code>交叉熵损失函数</code>来表示:$$ LOSS=−(y∗log(D(x))+(1−y)log(1−D(G(z)))) $$</p>
<p>y是标签label，真图片为1，假图片为0，D(x)是判断器的输出，即图片为真的概率</p>
<p>GAN模型的目标函数 :</p>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674890690311.png" alt="img"> </p>
<p>想要训练判别器就要让V越大越好，想要训练生成器就要让V越小越好</p>
<h2 id="Deepfake-Detection-Challenge–DFDC"><a href="#Deepfake-Detection-Challenge–DFDC" class="headerlink" title="Deepfake Detection Challenge–DFDC"></a>Deepfake Detection Challenge–DFDC</h2><blockquote>
<p>Reference：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/564661269">Deepfake Detection综述</a></p>
<p><a target="_blank" rel="noopener" href="http://scis.scichina.com/cn/2021/SSI-2020-0064.pdf">可视身份深度伪造与检测-彭春蕾等</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u014380165/article/details/98453672">pix2pix算法笔记_AI之路的博客-CSDN博客_pix2pix算法</a></p>
</blockquote>
<p>先了解一些Deepfake生成神经网络模型：</p>
<p><strong>Encoder-Decoder Networks-ED模型</strong>：</p>
<p>有一个编码器Encoder和两个解码器Decoder</p>
<p>用编码器从人脸A和人脸B上提取特征(将输入的图像转化成一个固定维度的向量)，分别训练出对应的解码器A和解码器B，解码器会根据特征输出近似的重建人脸</p>
<p>想要实现人脸替换，就将A人脸的特征向量输入解码器B</p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828525.png" alt="img"><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828626.png" alt="img"></p>
</blockquote>
<p><strong>卷积神经网络CNN:</strong></p>
<p>引入CNN的好处:</p>
<ul>
<li><p>CNN的卷积操作可以<strong>提取高阶的特征</strong></p>
</li>
<li><p>当网络变深时通过CNN池化层在Encoder上实现降维，在上采样层实现降维，<strong>减少参数提升效率</strong>啥的</p>
</li>
</ul>
<p><strong>循环神经网络RNN:</strong></p>
<p>RNN以及LSTM的“记忆性”是相较于CNN的一类优势；该优势使得该网络可以在处理deepfake video、deepfake audio数据时既可以提取到<strong>空间域信息</strong>（spatial information）也可以提取到<strong>时域的信息</strong>（temporal information）。 </p>
<p>RNN不会，先码着</p>
<p><strong>生成对抗网络GAN:</strong></p>
<p>生成器造假，判别器检验，不断对抗，最后就能尽可能生成逼真自然的伪造人脸</p>
<p><strong>Pix2Pix(deepnude就是用的这个):</strong></p>
<p><code>图像域image domain</code>:指的是图像被赋予了某些共同的属性。如轮廓图，彩色图就是不同的图像域</p>
<p>该网络是一种特殊的GAN网络(将GAN应用于有监督的图像到图像翻译)，利用成对训练数据进行训练，可以完成从一个图像域到另一个图像域的转换工作，如图像风格迁移、图像彩色化等图像翻译任务</p>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828627.png" alt="img"><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828628.png" alt="img"><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828629.png" alt="img"></p>
</blockquote>
<p><strong>CycleGAN：</strong></p>
<p>基于Pix2Pix网络的一种改进网络/基于循环一致性对抗网络的图像翻译方法，其可以通过不成对的图片进行训练，解决了非成对训练数据的场景下图像翻译问题， 具有更强的泛化能力。网络形成了一个由两个GANs组成的循环，用于将图像从一个域转换到另一个域，然后再返回，以确保与周期一致性损失的一致性。具体的， Hab 和 Hba 为 a 到 b 和 b 到 a 的域映射（生成器）， Db 和 Da 分别为图片 b ， a 的判别器。 </p>
<p>老师论文里给出的高阶一点的：</p>
<p><strong>StarGAN</strong>：韩国 Choi 等人通过训练统一的生成对抗网络模型，可以同时完成多种人脸属性的编辑伪造任务</p>
<p><strong>ProGAN</strong>：英伟达团队生成对抗网络的渐进式训练框架，从低像素尺度开始进行生成，并在训练过程中逐渐提高像素分辨率，最终生成高分辨率的虚假人脸。</p>
<p><strong>StyleGAN</strong>：以无监督学习的形式生成高质 量人脸图像的同时对图像细节进行控制， 以提高伪造人脸图像的逼真程度</p>
<p><strong>伪造检测方法</strong>：</p>
<p>现在主要有基于空域线索和基于时域线索的检测方法</p>
<p>空域:</p>
<ul>
<li><p>融合(blending)：生成的内容重新融合到图像帧时会产生一些伪影，检测方法比如边界检测、质量度量、频率分析（<strong>侧重于检测边缘的不一致性</strong>）</p>
</li>
<li><p>环境(environment)：伪造的脸部内容和图像帧的剩余部分可能是不协调的，比如面部变形过程中的残差、光照、保真度变化。（<strong>侧重于脸部和背景的不一致性</strong>）</p>
</li>
<li><p>取证(forensics)：分析模型在伪造产品中留下的细微特征和样式，比如GAN会留下独特的指纹可用于识别生成器、分析相机的独特传感器噪声（PRNU）识别粘贴的内容、寻找视频中帧序列的残差、寻找缺陷并预测和监测脸部特征点（<strong>如头部姿势往往不一致</strong>）</p>
</li>
</ul>
<p>时域:</p>
<ul>
<li><p>行为（behavior）：基于目标人物大量的数据，监测举止和其它<strong>行为异常</strong>，比如对已录制的目标人物素材库建模、在没有目标素材参考的情况下检测音视频片段中感知的情绪的差异。</p>
</li>
<li><p>生理（physiology）：基于生成的内容<strong>缺少生理信号</strong>的假设，比如监测心率识别伪造的面部、监测皮肤下血容量（脉搏）、监测不规则的眨眼模式，相反也有利用脉搏信号构建deepfake模型。</p>
</li>
<li><p>同步（synchronization）：<strong>不一致性</strong>也是一个detection因子，比如把语音和嘴巴附近的特征点相关联检测视频中嘴型和语音因素的不一致（如在嘴巴完全闭合的（B，P，M）音素上deepfake往往会失败）。</p>
</li>
<li><p>连贯（coherence）：实际的<strong>时间连贯性</strong>很难伪造产生，由此检测产生的伪影，比如使用RNN检测闪烁和抖动、使用LSTM只检测面部区域、使用成对的顺序帧训练分类器以及改进网络专注于监测帧的光流、（同一个作者）使用LSTM预测下一帧并监测重建误差。</p>
</li>
</ul>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828630.png" alt="img"> </p>
</blockquote>
<blockquote>
<p><img src="/2022/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/-166674926828631.png" alt="img"> </p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395533632">CVPR 2021 论文大盘点-人脸造假检测篇</a></p>
</blockquote>
<h2 id="对抗样本"><a href="#对抗样本" class="headerlink" title="对抗样本"></a>对抗样本</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/205035087">对抗鲁棒性简介 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hickey2048/p/14994305.html">对抗样本综述(一) - HickeyZhang - 博客园 (cnblogs.com)</a></p>
<p>为了应对对抗样本的威胁，学术界已经发表许多论文寻找保护深度神经网络的对策。</p>
<p>这些方法可以大致分为三种主要类型：</p>
<ul>
<li>隐藏梯度(gradient masking)：由于大多数攻击算法都是基于分类器的梯度信息，因此掩蔽或混淆梯度会混淆攻击机制。</li>
<li>鲁棒性优化(robust optimization): 这类研究展示了如何训练一个鲁棒的分类器，可以正确地分类对抗样本。</li>
<li>对抗检测(adversary detection): 这类方法试图在将样本输入深度学习模型之前，检查一个样本是良性的还是对抗的。</li>
</ul>
<p>按照攻击者的目标，对抗攻击可以分为poisoning attack 与evasion attack、targeted attack 与non-targeted attack。</p>
<p>poisoning attack是指攻击者在DNN算法的训练数据库中插入/修改几个假样本的攻击算法。这些假样本可能会导致训练过的分类器失败。它们可能会导致精度差，或对某些给定的测试样本的错误预测结果。poisoning attack是在模型训练过程中攻击，以使模型train不好。</p>
<p>在evasion attack中，分类器是固定的，通常在普通测试样本上具有良好的性能。攻击者无法改变分类器模型或其参数，但他们制作了一些分类器无法识别的假样本即对抗样本。换句话说，对手生成一些欺诈的例子来逃避分类器的检测。例如，在自动驾驶车辆中，在停车标志上粘贴几条磁带会混淆车辆的道路标志识别器。</p>
<p><strong>无目标攻击</strong>（Non-Target Attack）和<strong>有目标攻击</strong>（target Attack），前者攻击者只需要让模型出错即可，能够让模型不可用；后者攻击者希望通过输入控制模型的输出，能够让模型为攻击者所用。</p>
<p>在targeted attack中，假设对于原来的输入x(x是特征向量)，分类器的输出是y，攻击者对x添加扰动后形成特征向量x’，并期望分类器输出攻击者想要得到的输出t(对于x’，正确的分类结果期望是y)。例如，欺诈者可能伪装成该公司高度可信的客户以逃避金融公司的信用评估模型的监测。</p>
<p>如果攻击者只是想要扰动x到x’，使得分类器输入x’时输出不是y(对于x’，模型的训练者期望得到的正确的分类结果是y)而可以是其他任何的输出，那么这样的攻击就是non-targeted attack。</p>
<p>[对抗攻击——优化噪声的艺术 - 知乎 (zhihu.com)](<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341533105#:~:text=%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%EF%BC%88Adversarial">https://zhuanlan.zhihu.com/p/341533105#:~:text=对抗攻击（Adversarial</a> Attack）是指向输入数据中添加一些无法被人类察觉的噪声，使得模型对输入数据做出错误的判断，添加的噪声称为对抗扰动（Adversarial,Perturbation），而添加噪声后得到的样本则被称为对抗样本（Adversarial Example）。)</p>
<p>数字世界，物理世界的对抗例子</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/09/15/ctf/reverse/%E6%AF%8F%E6%97%A5%E5%8D%9A%E5%AE%A2/9.15-%E9%80%86%E5%90%91%E5%89%8D%E6%B2%BF%E6%96%B9%E5%90%91%E8%AE%BA%E6%96%87/" rel="next" title="9.15-New Frontiers of Reverse Engineering">
                <i class="fa fa-chevron-left"></i> 9.15-New Frontiers of Reverse Engineering
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/celeb-df%E6%95%B0%E6%8D%AE%E9%9B%86/" rel="prev" title="Celeb-DF数据集">
                Celeb-DF数据集 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="" />
          <p class="site-author-name" itemprop="name"></p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">95</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E7%BA%B2-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%B5%84%E6%BA%90"><span class="nav-number">1.</span> <span class="nav-text">人工智能大纲&#x2F;学习路线&#x2F;资源</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B7%AF%E7%BA%BF-%E8%B5%84%E6%BA%90"><span class="nav-number">1.1.</span> <span class="nav-text">路线&#x2F;资源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">2.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E5%85%83-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">2.1.</span> <span class="nav-text">神经元&#x2F;激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.</span> <span class="nav-text">感知机&#x2F;损失函数&#x2F;梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">2.3.</span> <span class="nav-text">多层感知机&#x2F;反向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BD%9C%E7%94%A8-%E6%9C%AC%E8%B4%A8"><span class="nav-number">2.4.</span> <span class="nav-text">神经网络的作用&#x2F;本质</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN"><span class="nav-number">3.</span> <span class="nav-text">卷积神经网络CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%86%E5%8F%B2%E5%8F%91%E5%B1%95"><span class="nav-number">3.1.</span> <span class="nav-text">历史发展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%84%E6%88%90"><span class="nav-number">3.2.</span> <span class="nav-text">组成</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9CGAN"><span class="nav-number">4.</span> <span class="nav-text">生成对抗网络GAN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deepfake-Detection-Challenge%E2%80%93DFDC"><span class="nav-number">5.</span> <span class="nav-text">Deepfake Detection Challenge–DFDC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC"><span class="nav-number">6.</span> <span class="nav-text">对抗样本</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hzlg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
