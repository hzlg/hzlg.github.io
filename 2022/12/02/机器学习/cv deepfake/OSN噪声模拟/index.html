<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,论文," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="OSN噪声模拟 将OSN有损操作分为可预测噪声与不可预测噪声,残差学习得到可预测噪声模型,使用对抗性噪声生成策略生成不可预测噪声">
<meta property="og:type" content="article">
<meta property="og:title" content="OSN噪声模拟">
<meta property="og:url" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/index.html">
<meta property="og:site_name" content="hzlg&#39;s blog">
<meta property="og:description" content="OSN噪声模拟 将OSN有损操作分为可预测噪声与不可预测噪声,残差学习得到可预测噪声模型,使用对抗性噪声生成策略生成不可预测噪声">
<meta property="og:locale">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069899085.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069108452.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069108441.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069899085.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753070299547.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753070299548.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753070299549.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995510.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995511.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995512.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995513.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995514.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995515.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995516.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995517.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995518.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995519.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995620.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995621.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995622.png">
<meta property="og:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995623.png">
<meta property="article:published_time" content="2022-12-01T16:00:00.000Z">
<meta property="article:modified_time" content="2024-09-15T13:28:17.031Z">
<meta property="article:author" content="hzlg">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069899085.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://hzlg.github.ioz/2022/12/02/机器学习/cv deepfake/OSN噪声模拟/"/>





  <title>OSN噪声模拟 | hzlg's blog</title>
  














<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">hzlg's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">笔记、日常</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hzlg.github.ioz/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hzlg's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">OSN噪声模拟</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-12-02T00:00:00+08:00">
                2022-12-02
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2024-09-15T21:28:17+08:00">
                2024-09-15
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>OSN噪声模拟</p>
<p>将OSN有损操作分为可预测噪声与不可预测噪声,残差学习得到可预测噪声模型,使用对抗性噪声生成策略生成不可预测噪声</p>
<blockquote>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069899085.png" alt="img" style="zoom:67%;"> 
</blockquote>
<span id="more"></span>

<h2 id="Github链接阅读"><a href="#Github链接阅读" class="headerlink" title="Github链接阅读"></a>Github链接阅读</h2><p><a target="_blank" rel="noopener" href="https://github.com/HighwayWu/ImageForensicsOSN">https://github.com/HighwayWu/ImageForensicsOSN</a></p>
<p>图像编辑软件滥用导致数字图像伪造情况增加，难以判别图像的真实性，经过在线社交网络（OSN，如微博、微信、facebook等）的一些有损操作，如压缩、调整大小后，虚假的图片更加难以检测与辨别。如下图，左边的图片最右边的人是拼接上去的，最右边的是经过DFCN以及本检测方法检测后的结果，分别对原伪造图以及经过OSN传输后的伪造图进行检测，DFCN只在原伪造图有较好的表现效果，但对传输过后的伪造图表现不尽如人意。但本检测方法就很好。</p>
<blockquote>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069108452.png" alt="img" style="zoom:50%;"> 
</blockquote>
<p>为了对抗OSN共享的伪造行为，在这项工作中，提出了一种新的鲁棒训练方案。首先，我们设计了一个基线探测器，该探测器在最近的证书伪造检测比赛中名列前茅。然后，我们对OSN引入的噪声进行彻底分析，并将其解耦为两部分，即<strong>可预测噪声</strong>和<strong>不可预测的噪声</strong>，它们分别建模。前者模拟OSN的公开（已知）操作引入的噪声，而后者的设计不仅完成前一个，还要考虑探测器本身的缺陷。我们最终将建模噪声整合到一个强大的训练框架中，显着提高了图像伪造检测器的鲁棒性。培训计划和相应测试阶段的概述如下</p>
<p>图：训练阶段：</p>
<ul>
<li>stage1训练：<ul>
<li>数据集D1（real）的原始图片通过OSN传输，去掉原图像，得到OSN传输公开操作<strong>引入的噪声</strong>；</li>
<li>通过网络传输，进行<strong>深度残差学习</strong>，再使用<strong>diff.jpeg</strong>(可微分jpeg压缩算法压缩图片），去掉原图像，得到<strong>可预测噪声</strong>。</li>
<li>两种处理方式相差得到不可见噪声。</li>
</ul>
</li>
<li>stage2建模：<ul>
<li>数据集D2（fake）的原始图片网络传输后进行第一步相同的深度残差学习，diff.jpeg压缩图像，再加上（残差学习学习得来的）噪声，对其进行噪声分析检测。</li>
</ul>
</li>
<li>stage3对噪声建模：<ul>
<li>对噪声建模分析计算。(update: 通过<strong>对抗性噪声生成策略</strong>对不可见噪声的建模)</li>
</ul>
</li>
<li>stage4训练：<ul>
<li>进行伪造检测，具体方法是原伪造图像的检测结果和上一步已经加入噪声的压缩过的图像基线探测器的结果进行比较，将比较结果继续传给噪声检测进行分析建模</li>
<li>最后，使用学习过的基线探测器进行被OSN处理过的图片的伪造检测。</li>
</ul>
</li>
</ul>
<blockquote>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069108441.png" alt="img" style="zoom:67%;"> 
</blockquote>
<h2 id="论文详细阅读"><a href="#论文详细阅读" class="headerlink" title="论文详细阅读"></a>论文详细阅读</h2><p><strong>第一个关键问题是对 OSN 有损操作引入的噪声进行分析和建模。</strong></p>
<p><strong>困难：</strong>目前的网络平台没有公开处理传输图像的过程，仅有部分操作是已知的，其余大部分操作都未知（比如Facebook的增强过滤操作）更重要的是，OSN 经常调整他们的图像处理管道，这对建模造成了更多的挑战。</p>
<p><strong>目标：</strong>设计一种强大的图像伪造检测方法来应对 OSN 中的有损操作。</p>
<p><strong>数据集：</strong>公开伪造的数据集超过5000个项目（基于现有的四个数据集：<strong>DSO</strong> , <strong>Columbia</strong> , <strong>NIST</strong> ，<strong>CASIA</strong>和三个OSN平台：<strong>Facebook</strong>，<strong>微博</strong>，<strong>微信</strong>）</p>
<p>相关工作：</p>
<h3 id="1-图像伪造检测"><a href="#1-图像伪造检测" class="headerlink" title="1.图像伪造检测"></a>1.图像伪造检测</h3><p>现在已经有很多图像伪造检测方法了</p>
<h3 id="2-OSN："><a href="#2-OSN：" class="headerlink" title="2.OSN："></a>2.OSN：</h3><p>几乎所有 OSN 都以有损方式处理上传的图像。分为三个阶段：1）<strong>调整大小</strong>    2）<strong>增强过滤</strong>    3）<strong>JPEG压缩</strong></p>
<p>如果图像的分辨率高于 2048 像素，则会应用调整大小，在此之后，图像中的一些选定块经过高度自适应和复杂的增强滤波，因为他们的自适应性，很难精确的知道这些增强滤波操作）</p>
<p>图像经过一轮 JPEG 压缩，质量因子 (QF) 根据图像内容自适应确定。（Facebook的QF因子范围在71到95之间）不同平台的图像有损操作不同，但仍有许多相似的地方。</p>
<h3 id="3-针对-OSN-传输的鲁棒图像伪造检测"><a href="#3-针对-OSN-传输的鲁棒图像伪造检测" class="headerlink" title="3.针对 OSN 传输的鲁棒图像伪造检测"></a>3.针对 OSN 传输的鲁棒图像伪造检测</h3><p>关键技术：适当地模拟由 OSN 传输所引起的退化</p>
<p>可预测噪声可以对应引起伪造检测退化源明确的情况，但不可见噪声是所有不明确源的一个结合，包括未知的建模、参数、训练和测试 OSN 之间的差异，甚至有些完全未知的退化源。</p>
<p>通过向训练过程中添加模拟的OSN噪声，检测器有望学习更多可以在 OSN 传输中幸存下来的通用特征，从而使整体伪造检测性能显着提高。</p>
<p><strong>stage1、2：</strong>通过可微网络模拟可预测噪声(训练网络得到超多可预测噪声,就能知道噪声的分布)</p>
<p><strong>stage3：</strong>通过对抗性噪声生成策略对不可见噪声</p>
<p><strong>stage4：</strong>图像伪造检测器（fθ）的实际鲁棒训练</p>
<blockquote>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753069899085.png" alt="img" style="zoom:67%;"> 
</blockquote>
<p>复合噪声可以表示为可预测噪声τ和不可预测噪声ξ</p>
<p>$$δ = τ + ξ $$</p>
<p>伪造图像x：</p>
<p>采样两个三通道<strong>彩色图像p</strong>(一个像素点由三个值表示)</p>
<p>和一个单通道<strong>二进制掩码y</strong>(一个像素点由一个值表示,伪造的像素点值为1，其他像素点值为0)</p>
<p>伪造图像x可以表示为p和y的像素值乘积:</p>
<p>$$x = p1 ⊙ (1 − y) + p2 ⊙ y $$ </p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/LXYnizhan/article/details/92659905">对图像处理中掩码的理解_LXYnizhan的博客-CSDN博客_图像掩码</a></p>
<p>图像通道:对于一张H×W的彩色图像，图像矩阵实际上就是由H×W个（R,G,B）这样的向量组成，也就是一个3维的矩阵，其中（R,G,B）对应到了第三维上的取值。 具体在python-opencv中，表示h*w大小的三通道图像的示意图如下</p>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753070299547.png" alt="img" style="zoom:50%;"> 

<p>使用OpenCV读取并打印高宽为3*4三通道的RGB彩色图片，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img=cv2.imread(<span class="string">&#x27;3.png&#x27;</span>,<span class="number">1</span>)<span class="comment">#返回RGB彩色图像</span></span><br><span class="line"><span class="built_in">print</span>(img) <span class="comment">#打印代表灰度图像的3维矩阵</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>图像伪造检测器fθ在复合噪声δ下的鲁棒训练可以公式化为</p>
<p>$$arg,min_θ \frac{1}{N}\sum_{i=1}^{N}E_{P(δ)}{Lb(f_θ(x_i + δ), y_i)} $$ </p>
<p>数学中 arg min的意思：arg min 就是使后面这个式子达到最小值时变量取值</p>
<p>$$将加完噪声后的伪造图像x_i+δ经过检测器f_θ得到检测结果f_θ(x_i + δ) $$ </p>
<p>$$与用于拼接的假图片原图对比得到二元交叉熵损失函数Lb $$ </p>
<p>$$求损失函数关于噪声分布P（δ）的期望E $$ </p>
<p>$$对N张图片的期望求均值,修改参数θ使得该均值最小 $$ </p>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753070299548.png" alt="img" style="zoom:67%;"> 

<p>若认为两个噪声分量τ和ξ是相关的，鲁棒训练方案可以写为：</p>
<p>$$arg,min_θ \frac{1}{N}\sum_{i=1}^{N}E_{P(τ)}{E_{P(ξ|τ)}{Lb(f_θ(x_i + δ), y_i)}} $$ </p>
<p>概率论有个重期望公式：$$E(X)=E[E(X∣Y)]$$ </p>
<p>其他就和上面的一样,就是求损失函数期望,改参数</p>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-16753070299549.png" alt="img" style="zoom:67%;"> 

<p>在具有足够数量的噪声样本时，可以有效且准确地计算这些期望值。</p>
<p>所以接下来的关键任务就是对<em>P</em>(τ)，P(ξ|τ)进行建模。</p>
<h3 id="3-1-对分布-P-τ-建模"><a href="#3-1-对分布-P-τ-建模" class="headerlink" title="3.1 对分布 P(τ) 建模"></a>3.1 对分布 P(τ) 建模</h3><p>对于图像 xi 和固定的 OSN 平台，产生的噪声可以很容易地计算为</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995510.png" alt="img"> </p>
<p>函数 OSN(·) 反映了给定 OSN 平台进行的所有操作，τ i 取决于 xi。</p>
<p>通过这种方式，我们可以生成大量噪声样本，这些样本可用于对 P(τ) 的分布进行建模。但这种建模方案有很大的文图，因为实际应用的时候，处理后的图像OSN(xi)需要通过上传xi到具体的OSN平台来获取，一方面，这样的操作很耗时； 另一方面，许多 OSN 不允许太多次的上传/下载操作。</p>
<p>为了解决这一问题，我们用深度网络替代模仿 OSN 操作。</p>
<p>具体来说，为了与 OSN 平台中的图像处理管道保持一致，我们训练了一个 <strong>DNN 模型</strong>，该模型明确嵌入了一个<strong>可微分层</strong>来描述 JPEG 压缩。对于一个输入的图像xi,我们的目标是学习映射 gφ，其中 gφ 是具有可训练参数 φ 的网络，用于预测 OSN 输出，我们为 gφ 采用 <strong>U-Net</strong> 架构（因为它本质上是图像到图像的映射）。训练好的 gφ* 在stage2用于对P(τ)进行建模。</p>
<blockquote>
<p>Unet：</p>
<p>卷积提取特征+池化降低特征维度，都使特征图变小了,即进行了下采样 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/307839910">1</a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/baidu_14831657/article/details/60570765">2</a></p>
<p>反卷积+上反池化 扩大特征图大小(缩小再放大后丧失了部分信息,只剩下主要的特征),拼接原特征图,</p>
<p>这个结构就是先对图片进行<strong>卷积和池化</strong>，比方说一开始的图片是224x224的，那么就会变成112x112，56x56,28x28,14x14四个不同尺寸的特征。然后我们对14x14的特征图做<strong>上采样或者反卷积</strong>，得到28x28的特征图，这个28x28的特征图与之前的28x28的特征图进行通道上的<strong>拼接</strong>concat，然后再对拼接之2后的特征图做卷积和上采样，得到56x56的特征图，再与之前的56x56的特征拼接，卷积，再上采样，经过四次上采样可以得到一个与输入图像尺寸相同的224x224的预测结果。</p>
<img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995511.png" alt="img" style="zoom: 50%;"> 
</blockquote>
<p>在训练阶段，我们成对收集输入图像xi和OSN以离线方式传输版本 OSN(xi) 。</p>
<p>训练 gφ 的目标函数可以表示为</p>
<blockquote>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995512.png" alt="img"> </p>
</blockquote>
<p>引入残差学习结构：</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995513.png" alt="img"> </p>
<p>残差学习有利于模型优化，显着提高建模性能。</p>
<p>我们明确地将一个特殊的 JPEG 层集成到模型中以更好地生成结构，为了保证端到端优化，我们需要确保 JPEG 压缩的每一步都保持可微分，所以，我们用一个可微分的函数：</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995514.png" alt="img"> </p>
<p><em>Jq：</em>表示具有给定 q 的可微 JPEG 层</p>
<p>q都是在[71,95]范围内均匀采样（Facebook）</p>
<p>直接推导出噪声τi：</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995515.png" alt="img"> </p>
<p>其中 φ* 是通过求解优化问题方程得到的。</p>
<p>q和JPEG压缩有关</p>
<p>然后可以实施蒙特卡洛 (MC) 采样方案来生成大量噪声样本，用于对分布 P(τ) 进行建模</p>
<h3 id="3-2-对条件分布-P-ξ-τ-建模"><a href="#3-2-对条件分布-P-ξ-τ-建模" class="headerlink" title="3.2 对条件分布 P(ξ|τ ) 建模"></a>3.2 对条件分布 P(ξ|τ ) 建模</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45521594/article/details/104629732">对抗样本入门详解_pinn山里娃的博客-CSDN博客_对抗样本</a></p>
<p>[<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32784766">论文笔记]Explaining &amp; Harnessing Adversarial Examples</a></p>
<p>[对抗攻击——优化噪声的艺术](<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341533105#:~:text=%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%EF%BC%88Adversarial">https://zhuanlan.zhihu.com/p/341533105#:~:text=对抗攻击（Adversarial</a> Attack）是指向输入数据中添加一些无法被人类察觉的噪声，使得模型对输入数据做出错误的判断，添加的噪声称为对抗扰动（Adversarial,Perturbation），而添加噪声后得到的样本则被称为对抗样本（Adversarial Example）。)</p>
</blockquote>
<p>我们加入噪声项 ξ 的原因是可预测的噪声 τ 无法完全捕获实践中遇到的噪声行为。</p>
<p>所以关键问题是如何对不可见噪声 ξ 进行正确建模</p>
<p>可以转变角度，不考虑噪声，考虑检测器fθ：</p>
<p>注意那些降低检测性能的因素，而忽略那些对检测性能影响不大的因素</p>
<p>所以我们引入了<strong>对抗性噪声</strong>：人类感官无法察觉，但却可以导致严重的模型输出错误。</p>
<p>因为不可见噪声其实很小，同时可以欺骗检测器。（高度扭曲的图像不可见噪声会大一点，但高度扭曲的图像会偏离伪造的目的）</p>
<p><strong>所以对抗性噪声是不可见噪声的很好的替代品</strong></p>
<p>何为对抗？我们不再优化参数，我们优化输入——更加确切地说，我们优化输入数据的噪声。</p>
<p>通过将噪声 ξ 添加到原始正常示例创建，<strong>跨越决策边界</strong>(导致错误分类)<strong>，可以发现，噪声 ξ 通常振幅较小，我们建议将 ξ 的方向设置为沿成本函数(所有损失函数总和的平均值)相对于输入的梯度，以</strong>最小化噪声能量(不是说按照输入的梯度能降低噪声,是按照输入的梯度就能用最小的噪声能量达到最大的分类混淆)。</p>
<blockquote>
<p>找到一张对抗性噪声的图，帮助理解两个损失函数/梯度是干什么的</p>
<p>对抗性噪声问题可以分解为“<strong>导致错误分类</strong>”和“<strong>最小化扰动</strong>”</p>
<p><del>在第一阶段,搜索导致错误分类的对抗性样本为首要目标,因此算法沿着<strong>错误分类损失函数的梯度1方向</strong>搜索,同时动态评估距离边界的距离,调整搜索步幅,以最快速度<strong>穿越分类边界</strong>。在当前解跨越分类边界之后(<strong>导致错误分类</strong>),算法进度第二阶段,该阶段算法以<strong>减小扰动大小</strong>为首要目标,为避免当前解再次跨越分类边界,本文提出使其沿边界方向,即<strong>梯度2的法向量方向</strong>搜索(没懂,沿谁的边界方向?)。</del> </p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995516.png" alt="img"> </p>
</blockquote>
<p>若不考虑对抗性噪声,检测器fθ想要优化参数θ,需要求fθ(xi)和yi的损失函数,计算梯度▽xi,更新参数θ</p>
<p>若增加了对抗性噪声,对抗扰动会使得样本乘上权重系数后变动θξ,若ξ为sign(▽xi),就能使得变动最大</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995517.png" alt="img"> </p>
<p>S是sign函数,当x&gt;0，sign (x)=1;当x=0，sign (x)=0; 当x&lt;0， sign (x)=-1,这样生成的对抗样本可以保证对抗样本和原始样本之间的距离不超过步长ϵ 。</p>
<p>在加入这些对抗性噪声到训练里，期望使学习的模型不仅对特定的对抗性噪声而且对更普遍的看不见的噪声具有鲁棒性。</p>
<p>（11）的结果取决于输入xi</p>
<p>为了全面增强检测器的泛化能力，我们建议将对抗性噪声的方向调整为全局梯度方向。通过随机选择的训练数据集子集的随机近似方法。更具体地说，对于第 (t + 1) 个输入 xt+1，可以将 ξt+1（以 τ 为条件）设置为从前 t 个输入计算的平均梯度，即</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995518.png" alt="img"> </p>
<p>ξ0 =0，（12）可以用来估计梯度平均值，它只反映特定已知数据（训练数据）的梯度。我们建议在小范围内扰动 ξt+1，使用参数化模型来表征平均梯度会更理想。为了找到适合平均梯度的模型，我们首先采用数据驱动的方法，分析从训练过程中随机选择的1000 个 ξ 样本的统计数据。</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995519.png" alt="img"> </p>
<p>1000个样本2D可视化。可以发现中间比较密集，远离中间的会逐渐消失。这种现象建议我们使用<strong>高斯分布</strong>来建模平均梯度模拟平均梯度：</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995620.png" alt="img"> </p>
<p>其中 σ 是用于控制方差的经验设置参数</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995621.png" alt="img"> </p>
<p>并且∈是用于<strong>约束扰动幅度以避免不必要的模型退化的参数</strong>。</p>
<p>有了方程（13）中的参数模型，我们可以很容易地生成噪声样本来对P(ξ|τ) 建模。</p>
<p>$$xi是图像,gφ是要训练的网络,φ是网络的参数 $$</p>
<p>$$xi+gφ(xi)是残差网络的输出 $$</p>
<p>$$Jq()是经过一层可微压缩层(可微是为了能求梯度) $$</p>
<p>$$Lr()是求损失函数 $$</p>
<p>$$∇φ()是求梯度,∇φ(Lr(Jq(xi + gφ(xi)), yi))就是图像xi经过残差网络变为xi + gφ(xi),经过可微压缩层变为Jq(xi + gφ(xi)),和原图yi对比得到损失函数Lr(Jq(xi + gφ(xi)), yi),最后求损失函数的梯度 $$</p>
<p>$$得到损失函数梯度后根据学习率lφ更新网络的参数φ,使得损失函数减小 $$</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995622.png" alt="img"> </p>
<p>选个质量因子,表示JPEG压缩结果</p>
<p>根据训练好的网络生成<strong>可预测噪声</strong></p>
<p>以xi的平均梯度u为位置参数根据高斯分布生成<strong>不可预测噪声</strong></p>
<p>计算损失函数,求θ的梯度,以更新参数θ使得损失函数最小</p>
<p><img src="/2022/12/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cv%20deepfake/OSN%E5%99%AA%E5%A3%B0%E6%A8%A1%E6%8B%9F/-167530702995623.png" alt="img"> </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
            <a href="/tags/%E8%AE%BA%E6%96%87/" rel="tag"># 论文</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/11/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/channel/channel-wise%20%E5%AF%B9%E6%8A%97%E9%B2%81%E6%A3%92%E6%80%A7/" rel="next" title="channelwise 对抗鲁棒性">
                <i class="fa fa-chevron-left"></i> channelwise 对抗鲁棒性
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/12/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/channel/%E6%8C%9F%E6%8C%81%E6%94%BB%E5%87%BB/" rel="prev" title="模型劫持攻击">
                模型劫持攻击 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="" />
          <p class="site-author-name" itemprop="name"></p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">103</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Github%E9%93%BE%E6%8E%A5%E9%98%85%E8%AF%BB"><span class="nav-number">1.</span> <span class="nav-text">Github链接阅读</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E8%AF%A6%E7%BB%86%E9%98%85%E8%AF%BB"><span class="nav-number">2.</span> <span class="nav-text">论文详细阅读</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B"><span class="nav-number">2.1.</span> <span class="nav-text">1.图像伪造检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-OSN%EF%BC%9A"><span class="nav-number">2.2.</span> <span class="nav-text">2.OSN：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E9%92%88%E5%AF%B9-OSN-%E4%BC%A0%E8%BE%93%E7%9A%84%E9%B2%81%E6%A3%92%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B"><span class="nav-number">2.3.</span> <span class="nav-text">3.针对 OSN 传输的鲁棒图像伪造检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-%E5%AF%B9%E5%88%86%E5%B8%83-P-%CF%84-%E5%BB%BA%E6%A8%A1"><span class="nav-number">2.4.</span> <span class="nav-text">3.1 对分布 P(τ) 建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E5%AF%B9%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83-P-%CE%BE-%CF%84-%E5%BB%BA%E6%A8%A1"><span class="nav-number">2.5.</span> <span class="nav-text">3.2 对条件分布 P(ξ|τ ) 建模</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hzlg</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
